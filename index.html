<!DOCTYPE html>
<html>

<head>
<meta charset="utf-8" />
<meta name="viewport"
	content="width=device-width, initial-scale=1, maximum-scale=1" />
<meta name="description" content="" />
<meta name="author" content="" />



<title>Home</title>
<!-- BOOTSTRAP CORE STYLE CSS -->
<link href="assets/css/bootstrap.css" rel="stylesheet" />
<!-- VEGAS SLIDESHOW STYLE CSS -->
<link href="assets/plugins/vegas/jquery.vegas.min.css" rel="stylesheet" />
<!-- FONTAWESOME STYLE CSS -->
<link href="assets/css/font-awesome.min.css" rel="stylesheet" />
<!-- CUSTOM STYLE CSS -->
<link href="assets/css/style.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="assets/css/detail.css" />
<!-- GOOGLE FONT -->
<link href='http://fonts.googleapis.com/css?family=Open+Sans'
	rel='stylesheet' type='text/css' />
<link rel="stylesheet" href="assets/css/style.css">
<!--<link rel="stylesheet" href="assets/css/main.css">-->
<!--<link rel="stylesheet" href="assets/css/rangeslider.css">-->


</head>

<body data-spy="scroll" data-target="#menu">
	<div class="navbar navbar-inverse navbar-fixed-top scrollclass"
		id="menu">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse"
					data-target=".navbar-collapse">
					<span class="icon-bar"></span> <span class="icon-bar"></span> <span
						class="icon-bar"></span>
				</button>
				<a class="navbar-brand" href="#"><img src="assets/img/logo.jpg"
					alt="" style="max-height:40px" /></a>
			</div>
			<div class="navbar-collapse collapse">
				<ul class="nav navbar-nav navbar-right">
					<li><a href="https://github.com/harryandlina">HOME</a></li>
					<li><a href="https://github.com/harryandlina/SparkAIBench">SparkAIBench</a></li>
					<li><a href="#about">INTRODUCTION</a></li>
                    <li><a href="#step">HOW TO USE</a></li>
					<li><a href="#contact">CONTACT</a></li>
				</ul>
			</div>

		</div>
	</div>
	<!--NAVBAR SECTION END-->
	<div id="home">
		<div class="container">
			<div class="row">
				<div
					class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2 ">
					<div id="carousel-slider" data-ride="carousel"
						class="carousel slide">

						<div class="carousel-inner">
							<div class="item active">

								<h1>WELCOME TO HERE</h1>
							</div>
							<div class="item">
								<h1>INTRODUCE HOW TO USE THIS TOOL</h1>
							</div>
							<div class="item">
								<h1>PRODUCE THE AI WORKLOAD OF SPARK</h1>
							</div>
						</div>
						<!--INDICATORS-->
						<ol class="carousel-indicators">
							<li data-target="#carousel-slider" data-slide-to="0"
								class="active"></li>
							<li data-target="#carousel-slider" data-slide-to="1" class=""></li>
							<li data-target="#carousel-slider" data-slide-to="2" class=""></li>
						</ol>

					</div>

				</div>
			</div>
			<div class="row">
				<div
					class="col-lg-6 col-lg-offset-3 col-md-6 col-md-offset-3 col-sm-8 col-sm-offset-2  scrollclass">

					
					<p>SparkAIBench使用说明</p>
					<br /> <a href="#about" class="btn  btn-lg custom-btn-1"><i
						class="fa fa-home"></i>ABOUT </a> <a href="#services"
						class="btn  btn-lg custom-btn-1"><i class="fa fa-comments-o"></i>
						SERVICES </a> <a href="#contact" class="btn btn-lg custom-btn-1"><i
						class="fa fa-globe"></i> CONTACT </a>
				</div>
			</div>
		</div>

	</div>
	<!--HOME SECTION END-->
	<hr />
	<section id="about">
		<div class="container">
			<div class="row">
				<div
					class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2  text-center">
					<h2>INTRODUCTION</h2>
					<h1>
						
                        <a href="https://github.com/harryandlina/SparkAIBench">Link: SPARK AI BENCH</a>
					</h1>
				</div>
			</div>

			<div class="row ">
            <labal>
            <p>近年来，分布式机器学习工作负载正在迅速成为云计算领域的流行应用。现已提出了大量框架以并行方式执行的此类工作负载，例如Spark MLlib、BigDL和Tensorflow。训练数据规模的不断扩大和训练模式的快速发展带来了更高的学习精度，但同时也大大延长了训练时间。训练时间主要取决于得到的集群资源。基准测试可以针对人工智能负载的资源密集和耗时的特性进行测试，帮助系统操作员做出决策、调整资源供给和作业调度优化。</p>
            <p>现有的典型调度程序，如 YARN的调度程序，通常为每个工作负载分配固定数量的资源，而无法利用额外的可用资源。近年来出现了一种根据集群状态和资源情况的动态自适应的作业调度程序。其中，最先进的技术之一是利用深度强化学习（DRL）技术，以尝试和错误的方式训练神经网络，以获得最佳的调度决策。目前，基于DRL的调度程序主要通过运行工作负载生成的集群日志来训练模型，因为缺乏能够自动生成多样可定制的用户工作负载，这些工作负载大都是手动设置的。很容易发现，以手动方式生成工作负载可能会导致代理培训的结果不准确，而且过程非常复杂，但今天生成工作负载的主要工作并不是集中在人工智能领域，现有的一些框架所提供工作负载主要被用于特定的应用领域。总而言之，目前还无法自动生成用户自定义的人工智能工作负载。</p>
            <p>因此，我们设计并实现了SparkAIBench，它支持多样性人工智能算法、不同的输入数据大小以及参数化提交方法。SparkAIBench既支持传统的人工智能算法如朴素贝叶斯、SVM、Kmeans等，也支持Resnet，Inception等新型的人工智能算法。并且，SparkAIBench可通过调整输入数据大小或选择迭代次数来确定负载规模和消耗时间。</p>
            </labal>
			</div>
		</div>
	</section>

	<!--ABOUT SECTION END-->
	<hr />
    <section id="step" align="center">
    
    <div class="container" style="width:800px" align="left">
    <div class="row">
    <div
    class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2  text-center">
    <h2>HOW TO USE</h2>
    </div>
    </div>
    <div class="row ">
    <h3>1.配置环境</h3>
    <p>首先配置负载运行环境，所需运行环境如下:</br>
    Hadoop&nbsp;: 2.7.7</br>
    Scala&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: 2.11.8</br>
    Python&nbsp;&nbsp;:3.7.0</br>
    Spark&nbsp;&nbsp;&nbsp;&nbsp;:2.3.1</br>
    Java&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:1.8.0</br>
    </p>
    <b>1.1配置Hadoop</b>
    <p>
    Java：Java1.8或者以后的版本。</br>
    Hadoop：推荐版本为2.7.7，以后的版本也可以使用。</br>
    下载Hadoop：
    <a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.7/hadoop-2.7.7-src.tar.gz">https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.7/hadoop-2.7.7-src.tar.gz</a></br>
    </br>
    <b>（1）    解压Hadoop包</b></br>
    tar -zxvf hadoop-2.7.3.tar.gz</br>
    </br>
    <b>（2）    编辑配置文件</b></br>
    export JAVA_HOME=/path/to/java_home</br>
    </br>
    <b>（3）    在hadoop-env.sh中添加Java环境信息</b></br>
    export JAVA_HOME=/path/to/java_home</br>
    </br>
    <b>（4）    修改core-site.xml<b></br>
    &lt;configuration&gt;</br>
    &lt;property&gt;</br>
    &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master_node_hostname:9100&lt;/value&gt;</br>
    &lt;/property&gt;</br>
    &lt;property&gt;</br>
    &lt;name&gt;fs.defaultFS&lt;/name&gt;</br>
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</br>
    &lt;/property&gt;</br>
    &lt;/configuration&gt;</br>
    </br>
    <b>(5)修改hdsf-site.xml文件</b></br>
    &lt;configuration&gt; </br>
    &lt;property&gt; </br>
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</br>
    &lt;value&gt;/path/to/store/metadata&lt;/value&gt;</br>
    &lt;description&gt;&lt;/description&gt;</br>
    &lt;/property&gt;</br> &lt;property&gt; </br>
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</br>
    &lt;value&gt;/path/to/store/hdfs_data&lt;/value&gt;</br>
    &lt;description&gt;&lt;/description&gt; </br>
    &lt;/property&gt; </br>
    &lt;property&gt; </br>
    &lt;name&gt;dfs.replication&lt;/name&gt;</br>
    &lt;value&gt;replication_num&lt;/value&gt; </br>
    &lt;/property&gt; </br>
    &lt;/configuration&gt;</br>
    </br>
    （6）    把Hadoop路径添加到/etc/profile中</br>
    export HADOOP_HOME=your_hadoop_home_path</br>
    source /etc/profile</br>
    
    </p>
    
    <b>1.2配置Spark</b></br>
    <p>
    Java：1.8或以后版本</br>
    Scala：2.11.8或以后版本</br>
    Hadoop：2.7.7</br>
    下载spark：<a href="https://archive.apache.org/dist/spark/">https://archive.apache.org/dist/spark/</a></br>
    </br>
    （1）    解压spark文件：</br>
    tar spark-2.3.1-bin-hadoop2.7.tar</br>
    </br>
    （2）    修改配置文件：</br>
    在 _./conf/spark-env.sh中添加:</br>  export SPARK_DIST_CLASSPATH=$(hadoop classpath)</br>
    </br>
    （3）    在/etc/profile中添加spark信息：</br>
    export SPARK_HOME=/path/to/spark</br>
    export PATH=$PATH:$SPARK_HOME</br>
    export PATH = $PATH:$SPARK_HOME/bin</br>
    source /etc/profile</br>
    另需将2.0-SPARK_2.3-0.8.0.jar和opennlp-tools-1.6.0.jar移到spark-home对应路径下的jars文件夹中。</br>
    </br>
    </p>
    <b>1.3下载组件</b></br>
    <p>
    jar文件：</br>
    workload_bayes.jar</br>
    workload_FPGrowth.jar</br>
    workload_kmeans.jar</br>
    workload_lda.jar</br>
    workload_svm.jar</br>
    workload_lda.jar</br>
    workload_autoencoder.jar</br>
    workload_lenet.jar</br>
    workload_resnet.jar</br>
    workload_rnn.jar</br>
    workload_vgg.jar</br>
    </br>
    shell文件：</br>
    start.sh</br>
    </br>
    python文件：</br>
    start_workload.py</br>
    information_FB.py</br>
    
    
    </p>
    <h3>2.数据集</h3>
    </br>
     <b>2.1下载数据集</b>
     <p>
     MLlib和Facebook相关数据集可从Github上直接下载，BigDL相关数据集详细情况如下所示：</br>
     </br>
     Autoencoder需要MNIST数据集</br>
     <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></br>
     需要下载文件:</br>
     train-images-idx3-ubyte.gz</br>
     train-labels-idx1-ubyte.gz</br>
     解压后为train-images-idx3-ubyte和train-labels-idx1-ubyte</br>
     </br>
     LeNet需要MNIST数据集</br>
     <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></br>
     
    
    需要下载以下四个文件:</br>
     train-images-idx3-ubyte,</br>
     train-labels-idx1-ubyte</br>
     t10k-images-idx3-ubyte</br>
     t10k-labels-idx1-ubyte</br>
     </br>
     ResNet需要CIFAR-10数据集</br>
     <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></br>
     
     下载时选择下载二进制的版本，CIFAR-10 binary version</br>
     </br>
     VGG需要CIFAR-10数据集</br>
     <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></br>
     
     下载时选择下载二进制的版本，CIFAR-10 binary version</br>
     </br>
     RNN需要the Tiny Shakespeare Texts数据集</br>
     <a href="https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt">https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt</a></br>
     
    下载后请将其分为训练集（train.txt）和测试集（val.txt），命令如下所示</br>
     export LANG=en_US.UTF-8</br>
     head -n 8000 input.txt > val.txt</br>
     tail -n +8000 input.txt > train.txt</br>
     </p>
    <b>2.2配置数据集</b>
    <p>
    2.2.1将四个Facebook的tsv数据文件移到python脚本相同的路径里。</br>
    </br>
    2.2.2生成足够的MLlib使用的数据集，由于空间限制，GitHub每个MLlib数据集仅提供了三个事例数据集，需要使用脚本produce_workload.sh生成其他数据集，数据集递增倍数可设置。</br>
    &emsp;命令如下所示：</br>
    &emsp;bash produce_worklaod.sh &lt;size&gt;</br>
    size参数代表生成数据集递增的倍数。</br>
    
    然后将MLlib对应数据文件上传到HDFS中的/workload_data文件夹下。</br>
    &emsp;命令如下所示：</br>
    &emsp;hadoop fs –put /your/path/todata /workload_data</br>
    </br>
    2.2.3BigDL对应的数据文件路径需要在start.py文件中设置路径。</br>
    
    </p>
    <h3>3.运行脚本</h3>
    </br>
    &emsp;运行脚本可以分为两种方法，一种使用start_workload.py脚本批量提交负载，另一种通过使用start.sh脚本提交单个负载。</br>
    </br>
    <b>3.1批量提交负载</b>
    <p>
    提交负载：python start_workload.py &lt;size&gt;</br>
    size参数为提交作业的个数。</br>
    SparkAIBench通过组合不同算法负载和不同负载规模来模拟多种多样的负载，而且SparkAIBench已尽可能的减少使用该工具的复杂性。提交作业之前，需要核对start.py中各项参数是否符合要求，如BigDL文件路径等。</br>
    （1）如果对生成的负载没有特定要求，则可以直接运行start.py文件，就可以将生成的负载运行到spark上。</br>
    （2）如有特定要求，在start.py中可以指定各个算法负载出现的比例（默认出现比例都相等）；如对提交队列有要求，可以在start.py中指定队列名称和提交到各队列的作业比例。（默认2个队列，queueA和queueB，出现比例为1：1）</br>
    </br>
    </p>
    <b>3.2单个提交负载</b>
    </br>
    </br>
    <p>
    MLlib和BigDL负责都可以通过使用start.sh脚本调用运行</br>
    </p>
    
    <b>3.2.1MLlib相关负载：</b></br>
    <p>
    通过使用start.sh脚本，提交MLlib等相关负载，提交实例如下：</br>
    bash start.sh  &lt;algorithmname&gt; &lt;queue&gt; &lt;pathtojar&gt; &lt;size&gt;
    </br>
    参数说明如下：</br>
    &emsp;&emsp;algorithmname选择提交的算法名称：linear， kmeans， svm， bayes ，FPGrowth，lda</br>
    &emsp;&emsp;size选择提交的数据量大小，可选范围为1-8，1代表数据量最小，8代表数据量最多</br>
    &emsp;&emsp;    pathjar输入jar的绝对路径</br>
   &emsp;&emsp;    queue为提交到的队列名称</br>
    </br>
    </p>
    <b>3.2.2BigDL相关负载：</b></br>
    <p>
    通过使用start.sh脚本，提交rnn，autoencoder等BigDL等负载。提交实例如下：</br>
    bash start.sh  &lt;algorithmname&gt; &lt;queue&gt; &lt;pathtojar&gt; &lt;iterationtime&gt; &lt;pathtodata&gt;</br>
    参数说明如下：</br>
    &emsp;&emsp;    algorithmname选择需要的算法名称：rnn，autoencoder，lenet，resnet，vgg</br>
    &emsp;&emsp;    pathtojar输入jar的绝对路径</br>
    &emsp;&emsp;    pathtodata输入数据集所在的绝对路径</br>
    &emsp;&emsp;    iterationtime选择迭代的次数</br>
    &emsp;&emsp;    queue为提交到的队列名称</br>
    </br>
    
    </p>
    
    
    </div>
    </div>
    </section>
    
	<hr />
	<section id="contact">

		<div class="container">
			<div class="row">
				<div
					class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2  text-center">
					<h2>CONTACT</h2>
					<p>if you have any problem, please contact to us.</p>
				</div>
			</div>
			<div class="row ">
				<div
					class="col-lg-8 col-lg-offset-2 col-md-8 col-md-offset-2 col-sm-8 col-sm-offset-2 text-center">
					<form>
						
						<label>OUR EMAIL</label>
						<div class="form-group">
                        <p>Zifeng Liu: 1217750686@qq.com</p>
						

					</form>
				</div>

			</div>
		</div>
	</section>
	<!--CONTACT SECTION END-->
	<div class="footer">Copyright &copy; 2018.BIT</div>

	<!-- CORE JQUERY  -->
	<script src="assets/plugins/jquery-1.10.2.js"></script>
	<!-- BOOTSTRAP SCRIPTS  -->
	<script src="assets/plugins/bootstrap.js"></script>
	<!-- EASING SCROLL SCRIPTS PLUGIN  -->
	<script src="assets/plugins/vegas/jquery.vegas.min.js"></script>
	<!-- VEGAS SLIDESHOW SCRIPTS  -->
	<script src="assets/plugins/jquery.easing.min.js"></script>
	<!-- CUSTOM SCRIPTS  -->
	<script src="assets/js/custom.js"></script>
	<script>
		$(function() {
			var $document = $(document);
			var selector = '[data-rangeslider]';
			var $inputRange = $(selector);
	
			// Example functionality to demonstrate a value feedback
			// and change the output's value.
			function valueOutput(element) {
				var value = element.value;
				var output = element.parentNode.getElementsByTagName('output')[0];
	
				output.innerHTML = value;
			}
	
			// Initial value output
			for (var i = $inputRange.length - 1; i >= 0; i--) {
				valueOutput($inputRange[i]);
			}
			;
	
			// Update value output
			$document.on('input', selector, function(e) {
				valueOutput(e.target);
			});
	
		});
	</script>

</body>

</html>
